{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models.fasttext import load_facebook_model, _load_fasttext_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "# https://github.com/RaRe-Technologies/gensim/blob/68ec5b8ed7f18e75e0b13689f4da53405ef3ed96/gensim/models/_fasttext_bin.py#L162\n",
    "def _struct_unpack(fin, fmt):\n",
    "    num_bytes = struct.calcsize(fmt)\n",
    "    return struct.unpack(fmt, fin.read(num_bytes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "fin = gzip.open(\"e:/langon/resources/cc.zh.300.bin.gz\", \"rb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "magic, version = _struct_unpack(fin, '@2i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(793712314, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magic, version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FASTTEXT_FILEFORMAT_MAGIC = np.int32(793712314)\n",
    "_NEW_HEADER_FORMAT = [\n",
    "    ('dim', 'i'),\n",
    "    ('ws', 'i'),\n",
    "    ('epoch', 'i'),\n",
    "    ('min_count', 'i'),\n",
    "    ('neg', 'i'),\n",
    "    ('word_ngrams', 'i'),   # Unused in loading\n",
    "    ('loss', 'i'),\n",
    "    ('model', 'i'),\n",
    "    ('bucket', 'i'),\n",
    "    ('minn', 'i'),\n",
    "    ('maxn', 'i'),\n",
    "    ('lr_update_rate', 'i'),   # Unused in loading\n",
    "    ('t', 'd'),\n",
    "]\n",
    "header_spec = _NEW_HEADER_FORMAT\n",
    "new_format = magic == _FASTTEXT_FILEFORMAT_MAGIC\n",
    "model = {name: _struct_unpack(fin, fmt)[0] for (name, fmt) in header_spec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': 300,\n",
       " 'ws': 5,\n",
       " 'epoch': 1,\n",
       " 'min_count': 5,\n",
       " 'neg': 10,\n",
       " 'word_ngrams': 1,\n",
       " 'loss': 2,\n",
       " 'model': 1,\n",
       " 'bucket': 2000000,\n",
       " 'minn': 5,\n",
       " 'maxn': 5,\n",
       " 'lr_update_rate': 100,\n",
       " 't': 9.999999747378752e-06}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def _load_vocab(fin, new_format, encoding='utf-8'):\n",
      "    \"\"\"Load a vocabulary from a FB binary.\n",
      "\n",
      "    Before the vocab is ready for use, call the prepare_vocab function and pass\n",
      "    in the relevant parameters from the model.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    fin : file\n",
      "        An open file pointer to the binary.\n",
      "    new_format: boolean\n",
      "        True if the binary is of the newer format.\n",
      "    encoding : str\n",
      "        The encoding to use when decoding binary data into words.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    tuple\n",
      "        The loaded vocabulary.  Keys are words, values are counts.\n",
      "        The vocabulary size.\n",
      "        The number of words.\n",
      "    \"\"\"\n",
      "    vocab_size, nwords, nlabels = _struct_unpack(fin, '@3i')\n",
      "\n",
      "    # Vocab stored by [Dictionary::save](https://github.com/facebookresearch/fastText/blob/master/src/dictionary.cc)\n",
      "    if nlabels > 0:\n",
      "        raise NotImplementedError(\"Supervised fastText models are not supported\")\n",
      "    logger.info(\"loading %s words for fastText model from %s\", vocab_size, fin.name)\n",
      "\n",
      "    _struct_unpack(fin, '@1q')  # number of tokens\n",
      "    if new_format:\n",
      "        pruneidx_size, = _struct_unpack(fin, '@q')\n",
      "\n",
      "    raw_vocab = collections.OrderedDict()\n",
      "    for i in range(vocab_size):\n",
      "        word_bytes = io.BytesIO()\n",
      "        char_byte = fin.read(1)\n",
      "\n",
      "        while char_byte != _END_OF_WORD_MARKER:\n",
      "            word_bytes.write(char_byte)\n",
      "            char_byte = fin.read(1)\n",
      "\n",
      "        word_bytes = word_bytes.getvalue()\n",
      "        try:\n",
      "            word = word_bytes.decode(encoding)\n",
      "        except UnicodeDecodeError:\n",
      "            word = word_bytes.decode(encoding, errors='backslashreplace')\n",
      "            logger.error(\n",
      "                'failed to decode invalid unicode bytes %r; replacing invalid characters, using %r',\n",
      "                word_bytes, word\n",
      "            )\n",
      "        count, _ = _struct_unpack(fin, '@qb')\n",
      "        raw_vocab[word] = count\n",
      "\n",
      "    if new_format:\n",
      "        for j in range(pruneidx_size):\n",
      "            _struct_unpack(fin, '@2i')\n",
      "\n",
      "    return raw_vocab, vocab_size, nwords\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from gensim.models._fasttext_bin import _load_vocab\n",
    "import inspect\n",
    "print(inspect.getsource(_load_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_vocab, vocab_size, nwords = _load_vocab(fin, new_format, encoding=\"UTF-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wasp\n",
    "import pickle\n",
    "with open(wasp.get_resource_path(\"\", \"fasttext_vocab_freq.pkl\"), \"wb\") as fout:\n",
    "    pickle.dump(raw_vocab, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python37464bitee4611e995004e38ba0d4e22ff5ed92d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
